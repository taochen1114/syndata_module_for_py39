{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe98472e-683c-4ed8-8274-9c0518dbf4c2",
   "metadata": {},
   "source": [
    "# 合成資料生成模組 - python3.9 版本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a9a68-ccb2-4840-89f9-374baaad450a",
   "metadata": {},
   "source": [
    "## 環境建置\n",
    "Python 3.9.23\n",
    "\n",
    "1. 建立 virtualenv\n",
    "```\n",
    "python -m venv venv\n",
    "source venv/bin/activate\n",
    "```\n",
    "2. 安裝 core 套件（預先裝 wheel）\n",
    "```\n",
    "pip install --upgrade pip setuptools wheel\n",
    "# pip install -r requirements.txt\n",
    "pip install sdv==1.23.0\n",
    "pip install sdmetrics==0.21.0\n",
    "pip install pandas==2.3.0\n",
    "pip install numpy==2.0.2\n",
    "pip install scikit-learn==1.6.1\n",
    "pip install scipy==1.13.1\n",
    "pip install matplotlib==3.9.4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0115c346-8276-4822-812f-ba6e5fee3c23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "from sdv.single_table import GaussianCopulaSynthesizer, CTGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ece5cde-4357-4bd9-adf3-6e1bb72cba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_model(model_path, num_rows=1000, condition_dict=None):\n",
    "    logging.info(f\"Loading model from: {model_path}\")\n",
    "\n",
    "    if \"GaussianCopula\" in model_path:\n",
    "        model = GaussianCopulaSynthesizer.load(model_path)\n",
    "    elif \"CTGAN\" in model_path:\n",
    "        model = CTGANSynthesizer.load(model_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot determine model type from file name: {model_path}\")\n",
    "\n",
    "    if condition_dict:\n",
    "        logging.info(f\"Sampling with conditions: {condition_dict}\")\n",
    "        return model.sample_conditions(conditions=condition_dict, num_rows=num_rows)\n",
    "    else:\n",
    "        return model.sample(num_rows=num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0deffcd-2d3f-49e8-a71b-151afb54a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sythesizer(args, input_df=pd.DataFrame()):\n",
    "    \"\"\"Synthesize input dataframe data and return synthetic output.\"\"\"\n",
    "\n",
    "    # === Step 1: 若有 primary key，先轉為 str 避免 regex 檢查錯誤 ===\n",
    "    pri_key = args.primary_key\n",
    "    if pri_key and pri_key in input_df.columns:\n",
    "        input_df[pri_key] = input_df[pri_key].astype(str)\n",
    "\n",
    "    # === Step 2: 建構 metadata ===\n",
    "    # metadata = Metadata.detect_from_dataframe(data=input_df)\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(data=input_df)\n",
    "\n",
    "    if pri_key:\n",
    "        metadata.update_column(column_name=pri_key, sdtype=\"id\")\n",
    "        metadata.set_primary_key(pri_key)\n",
    "        logging.info(f\"Primary key '{pri_key}' set as sdtype='id'.\")\n",
    "\n",
    "    # === Step 3: Initialize model ===\n",
    "    if args.synth_model == \"GaussianCopula\":\n",
    "        print(\"Synthetic model arch: GaussianCopula\")\n",
    "        model = GaussianCopulaSynthesizer(metadata)\n",
    "    elif args.synth_model == \"CTGAN\":\n",
    "        if args.custom_setting:\n",
    "            print(\"Synthetic model arch: CTGAN (custom)\")\n",
    "            model = CTGANSynthesizer(\n",
    "                metadata=metadata,\n",
    "                epochs=args.epochs,\n",
    "                batch_size=args.batch_size,\n",
    "                generator_dim=tuple(args.gen_dim),\n",
    "                discriminator_dim=tuple(args.dis_dim),\n",
    "                verbose=True,\n",
    "            )\n",
    "        else:\n",
    "            logging.info(\"Synthetic model arch: CTGAN (default)\")\n",
    "            model = CTGANSynthesizer(metadata, verbose=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported synth_model: {args.synth_model}\")\n",
    "\n",
    "    # === Step 4: Fit model ===\n",
    "    print(\"Fitting synthetic model ...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(input_df)\n",
    "    print(f\"Training completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # === Step 5: Sample data ===\n",
    "    output_df = model.sample(num_rows=args.num_rows)\n",
    "\n",
    "    # === Step 6: Save model if specified ===\n",
    "    if args.save_model:\n",
    "        print(\"=== save Syn. Model file ===\")\n",
    "        model_name = f\"syn_model_{args.synth_model}\"\n",
    "        if args.custom_setting:\n",
    "            model_name += \"-c\"\n",
    "        model_name += \".pkl\"\n",
    "\n",
    "        output_dir = os.path.dirname(args.output_fpath) if args.output_fpath else args.output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        model_path = os.path.join(output_dir, model_name)\n",
    "\n",
    "        print(f\"Saving model to {model_path}\")\n",
    "        model.save(model_path)\n",
    "\n",
    "    # === Step 7: Save output CSV if specified ===\n",
    "    if args.save_output and args.output_fpath:\n",
    "        os.makedirs(os.path.dirname(args.output_fpath), exist_ok=True)\n",
    "        print(f\"Saving synthetic output to {args.output_fpath}\")\n",
    "        output_df.to_csv(args.output_fpath, index=False)\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e470f0e8-8388-4be2-b7ee-4d52c0c4187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_args(args_list=None):\n",
    "    \"\"\"Main Function\n",
    "    process input and do configs check\n",
    "    \"\"\"\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input_path\", type=str, default=\"data/train.csv\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, default=\"data/output/\")\n",
    "    parser.add_argument(\"--synth_model\", type=str, default=\"GaussianCopula\", help=\"sythetic model type\")\n",
    "    parser.add_argument(\"--primary_key\", type=str, default=\"\", help=\"primary key in your tabular data\")\n",
    "    parser.add_argument(\"--num_rows\", type=int, default=200, help=\"num rows of the output sythetic dataframe\")\n",
    "    parser.add_argument(\"--save_model\", action=\"store_true\", help=\"set for save model pkl file\")\n",
    "    parser.add_argument(\"--save_output\", action=\"store_true\", help=\"set for save output csv file\")\n",
    "    parser.add_argument(\"--save_report\", action=\"store_true\", help=\"set for save report csv and image files\")\n",
    "    \n",
    "    parser.add_argument(\"--custom_setting\", action=\"store_true\", help=\"set for custom setting in CTGAN and TVAE Model\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=300, help=\"set epochs for training CTGAN and TVAE Model\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=500, help=\"set batch size for training CTGAN and TVAE Model\")\n",
    "    parser.add_argument(\"--gen_dim\", type=int, nargs=\"+\", default=[256, 256], help=\"set gen dimension\")\n",
    "    parser.add_argument(\"--dis_dim\", type=int, nargs=\"+\", default=[256, 256], help=\"set dis dimension\")\n",
    "    \n",
    "    parser.add_argument(\"--input_syn_model\", type=str, default=None, help=\"path to your syn_data model file\")\n",
    "    parser.add_argument(\"--sample_condition\", type=str, default=None, help=\"path to your syn_data sample condition json file\")\n",
    "    parser.add_argument(\"--output_fpath\", type=str, default=None, help=\"set full file path for your syn_data output csv\")\n",
    "\n",
    "    return parser.parse_args(args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd717889-07a0-4c66-a948-55808ec43ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # logging.info(f\"contents of args.primary_key {args.primary_key}\")\n",
    "    # logging.info(f\"contents of args.custom_setting {args.custom_setting}\")\n",
    "    # logging.info(f\"contents of args.gen_dim {args.gen_dim}\")\n",
    "    # logging.info(f\"contents of args.dis_dim {args.dis_dim}\")\n",
    "    if not args.input_syn_model:\n",
    "        print(\"=== Train Synthetic Model and Generate Sample SynData csv ===\")\n",
    "        assert os.path.exists(args.input_path), f\"Can't find the input file at {args.input_path}.\"\n",
    "        assert os.path.exists(args.output_dir), f\"Can't find the output folder at {args.output_dir}.\"\n",
    "        assert args.synth_model in [\"GaussianCopula\", \"CTGAN\"]\n",
    "        # [\"GaussianCopula\", \"CTGAN\", \"CopulaGAN\", \"TVAE\"]\n",
    "\n",
    "        \n",
    "        input_path = args.input_path\n",
    "        output_dir = args.output_dir\n",
    "        # output_fname=args.output_fname\n",
    "\n",
    "        print(f\"input file path: {input_path}\")\n",
    "        print(f\"output directory: {output_dir}\")\n",
    "\n",
    "        input_df = pd.read_csv(input_path)\n",
    "        if args.primary_key:\n",
    "            assert args.primary_key in input_df.columns\n",
    "\n",
    "        # if \"Id\" in input_df.columns:\n",
    "        #     input_df = input_df.drop(columns=[\"Id\"])\n",
    "\n",
    "        output_df = data_sythesizer(args=args, input_df=input_df)\n",
    "\n",
    "        logging.info(\"output dataframe shape\")\n",
    "        logging.info(output_df.shape)\n",
    "        logging.info(\"output dataframe head(5)\")\n",
    "        logging.info(output_df.head())\n",
    "\n",
    "\n",
    "        if args.save_output:\n",
    "            print(\"=== save output csv file ===\")\n",
    "            \n",
    "            base = os.path.basename(input_path)\n",
    "            output_fname = (\n",
    "                os.path.splitext(base)[0] + \"_\" + args.synth_model + \"_output.csv\"\n",
    "            )\n",
    "            output_df.to_csv(os.path.join(output_dir, output_fname), index=False)\n",
    "            \n",
    "            print(f\"saved to {os.path.join(output_dir, output_fname)}\")\n",
    "\n",
    "    else:\n",
    "        print(\"=== Generate Synthetic Data from Syn. Model ===\")\n",
    "        model_path = args.input_syn_model\n",
    "        num_rows = args.num_rows\n",
    "        condition_fpath = args.sample_condition\n",
    "        output_fpath=args.output_fpath\n",
    "\n",
    "        print(f\"The Syn. Model Path: {model_path}\")\n",
    "        print(f\"Generate {num_rows} rows to {output_fpath}...\")\n",
    "        \n",
    "        assert os.path.exists(model_path), f\"Can't find the model_path pkl file: {model_path}.\"\n",
    "        if not condition_fpath:\n",
    "            output_df = get_data_from_model(model_path, num_rows=num_rows, condition_dict=None)\n",
    "        else:\n",
    "            assert os.path.exists(condition_fpath), f\"Can't find the sample_condition json file: {condition_fpath}.\"\n",
    "            assert condition_fpath[-5:] == \".json\", f\"{condition_fpath} must be a json file!\"\n",
    "            \n",
    "            with open(condition_fpath, \"r\") as f:\n",
    "                condition_dict = json.load(f)\n",
    "\n",
    "            output_df = get_data_from_model(model_path, num_rows=num_rows, condition_dict=condition_dict)\n",
    "\n",
    "        print(\"output dataframe shape\")\n",
    "        print(output_df.shape)\n",
    "        print(\"output dataframe head(5)\")\n",
    "        print(output_df.head())\n",
    "\n",
    "        if args.save_output:\n",
    "            print(f\"=== Save csv to {output_fpath} ===\")\n",
    "            output_df.to_csv(output_fpath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b9a68-9cde-41df-9f10-37ca6d26eff6",
   "metadata": {},
   "source": [
    "# 使用模組訓練合成資料模型 + 生成合成資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7031732c-6a25-4724-af80-80b95b1038af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generate Synthetic Data from Syn. Model ===\n",
      "The Syn. Model Path: output/syn_model_GaussianCopula.pkl\n",
      "Generate 6000 rows to output/syn_data.csv...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Loading model from: output/syn_model_GaussianCopula.pkl'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"{'EVENT': 'Load', 'TIMESTAMP': datetime.datetime(2025, 6, 18, 6, 15, 18, 452595), 'SYNTHESIZER CLASS NAME': 'GaussianCopulaSynthesizer', 'SYNTHESIZER ID': 'GaussianCopulaSynthesizer_1.23.0_e64b93aad4dc4a8e871d896a958cf61a'}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"The real data in '3SsnPorch' was stored as 'int64' but the synthetic data could not be cast back to this type. If this is a problem, please check your input data and metadata settings.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"{'EVENT': 'Sample', 'TIMESTAMP': datetime.datetime(2025, 6, 18, 6, 15, 18, 453529), 'SYNTHESIZER CLASS NAME': 'GaussianCopulaSynthesizer', 'SYNTHESIZER ID': 'GaussianCopulaSynthesizer_1.23.0_e64b93aad4dc4a8e871d896a958cf61a', 'TOTAL NUMBER OF TABLES': 1, 'TOTAL NUMBER OF ROWS': 6000, 'TOTAL NUMBER OF COLUMNS': 81}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output dataframe shape\n",
      "(6000, 81)\n",
      "output dataframe head(5)\n",
      "              Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley  \\\n",
      "0  sdv-id-GZCyfr          48       RL         82.0    10489   Pave   NaN   \n",
      "1  sdv-id-PcjWgv          86       RL         50.0     5545   Pave   NaN   \n",
      "2  sdv-id-SfwDTL          32       RL         77.0    14440   Pave   NaN   \n",
      "3  sdv-id-dVJhsp         138       RL         73.0    11653   Pave   NaN   \n",
      "4  sdv-id-KzRwOB         128       RL         68.0     8953   Pave   NaN   \n",
      "\n",
      "  LotShape LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
      "0      Reg         Lvl    AllPub  ...        0    NaN  MnPrv         NaN   \n",
      "1      IR1         Lvl    AllPub  ...        0    NaN    NaN         NaN   \n",
      "2      Reg         Lvl    AllPub  ...        0    NaN    NaN         NaN   \n",
      "3      Reg         Lvl    AllPub  ...        0    NaN  MnPrv         NaN   \n",
      "4      Reg         Lvl    AllPub  ...        0    NaN  MnPrv         NaN   \n",
      "\n",
      "  MiscVal MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0       6      8   2006        WD         Normal     144771  \n",
      "1    7140      1   2007        WD         Normal     105516  \n",
      "2    7938      2   2007        WD         Normal     247214  \n",
      "3    2636     11   2008        WD         Normal      86923  \n",
      "4     533      8   2010       New         Normal     317192  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "=== Save csv to output/syn_data.csv ===\n"
     ]
    }
   ],
   "source": [
    "args = set_args([\n",
    "    \"--input_syn_model\", \"output/syn_model_GaussianCopula.pkl\", # 合成資料生成模型路徑 \n",
    "    \"--output_fpath\", \"output/syn_data.csv\",   # 合成資料輸出路徑\n",
    "    \"--num_rows\", \"6000\",  # 生成的資料筆數\n",
    "    \"--save_output\"\n",
    "])\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3625de-100b-4215-8b14-020e77c290a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1265fab-e208-46c8-9baa-236c0ec19a4a",
   "metadata": {},
   "source": [
    "## 檢視真實資料與合成資料表單"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16c948f2-e417-4192-b8c1-9ecc713bf503",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/syn_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m real_data_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput/data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# 真實資料路徑\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m syn_data_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput/syn_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 合成資料預設檔名為: 真實資料檔名 + \"_GaussianCopula_output\"\u001b[39;00m\n",
      "File \u001b[0;32m~/prjt-synthetic-data/py39/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prjt-synthetic-data/py39/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/prjt-synthetic-data/py39/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prjt-synthetic-data/py39/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/prjt-synthetic-data/py39/venv/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/syn_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "real_data_df = pd.read_csv(\"input/data.csv\")  # 真實資料路徑\n",
    "syn_data_df = pd.read_csv(\"output/syn_data.csv\")  # 合成資料預設檔名為: 真實資料檔名 + \"_GaussianCopula_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de27b9-63dd-4d28-ba3b-da55a3e63c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91fc049e-b117-4269-8b6a-30b1252beaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>RM</td>\n",
       "      <td>83.117324</td>\n",
       "      <td>10146</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.984574</td>\n",
       "      <td>8350</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR3</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.197250</td>\n",
       "      <td>9486</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-250</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>195464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10334</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-32</td>\n",
       "      <td>10</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>151816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.922532</td>\n",
       "      <td>10055</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>7</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>RM</td>\n",
       "      <td>77.128277</td>\n",
       "      <td>7223</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-148</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>New</td>\n",
       "      <td>Normal</td>\n",
       "      <td>161592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10240</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-56</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>166694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>RL</td>\n",
       "      <td>99.136819</td>\n",
       "      <td>13482</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-57</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>333492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16833</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>142353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>RL</td>\n",
       "      <td>46.789488</td>\n",
       "      <td>10843</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-131</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>253741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   0          38       RM    83.117324    10146   Pave   NaN      Reg   \n",
       "1   1          26       RL    78.984574     8350   Pave   NaN      IR3   \n",
       "2   2          65       RL    70.197250     9486   Pave   NaN      Reg   \n",
       "3   3          17       RL          NaN    10334   Pave   NaN      IR1   \n",
       "4   4          72       RL    78.922532    10055   Pave   NaN      Reg   \n",
       "5   5          23       RM    77.128277     7223   Pave   NaN      Reg   \n",
       "6   6          73       RL          NaN    10240   Pave   NaN      IR1   \n",
       "7   7          45       RL    99.136819    13482   Pave   NaN      Reg   \n",
       "8   8          19       RL          NaN    16833   Pave   NaN      IR1   \n",
       "9   9          31       RL    46.789488    10843   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...       -4    NaN   NaN         NaN      16      1   \n",
       "1         Low    AllPub  ...       -5    NaN   NaN         NaN      65      7   \n",
       "2         Low    AllPub  ...        7    NaN   NaN         NaN    -250      5   \n",
       "3         Lvl    AllPub  ...        8    NaN   NaN         NaN     -32     10   \n",
       "4         Lvl    AllPub  ...        5    NaN   NaN         NaN     147      7   \n",
       "5         Lvl    AllPub  ...        9    NaN   NaN         NaN    -148      9   \n",
       "6         Lvl    AllPub  ...       -4    NaN   NaN         NaN     -56      4   \n",
       "7         Lvl    AllPub  ...       -3    NaN   NaN         NaN     -57      6   \n",
       "8         Lvl    AllPub  ...       -7    NaN   NaN         NaN     153      6   \n",
       "9         Lvl    AllPub  ...        8    NaN   NaN         NaN    -131      8   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     172605  \n",
       "1   2006        WD         Normal     122255  \n",
       "2   2008        WD         Normal     195464  \n",
       "3   2008        WD        Abnorml     151816  \n",
       "4   2010        WD         Normal     189342  \n",
       "5   2010       New         Normal     161592  \n",
       "6   2009        WD         Normal     166694  \n",
       "7   2008       New        Partial     333492  \n",
       "8   2007        WD        Abnorml     142353  \n",
       "9   2007        WD         Normal     253741  \n",
       "\n",
       "[10 rows x 81 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c92b8bd-cd7e-41c5-aa09-ba07df3f62e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
